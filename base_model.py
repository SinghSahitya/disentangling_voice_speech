# -*- coding: utf-8 -*-
"""base_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wPF-zvTyBt0G3sKll6Y5K6p_Oc1CShAu
"""

import torch
from torch import nn
from torch.utils.data import DataLoader,Dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pickle
from tqdm import tqdm
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence
import pickle


class SpeakerDataset(Dataset):
    def __init__(self, data_path):
        with open(data_path, 'rb') as f:
            self.data = pickle.load(f)
        self.speaker_mapping = {speaker: idx for idx, speaker in enumerate(set(d['speaker'] for d in self.data))}

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        sample = self.data[idx]
        features = torch.tensor(sample['features'], dtype=torch.float32)
        speaker_label = self.speaker_mapping[sample['speaker']]
        return features.T, speaker_label  # Transpose to [seq_len, feature_dim]


def custom_collate_fn(batch):
    features = [item[0] for item in batch]
    labels = [item[1] for item in batch]
    features_padded = pad_sequence(features, batch_first=True, padding_value=0.0)  # [batch_size, max_seq_len, feature_dim]
    labels = torch.tensor(labels, dtype=torch.long)
    lengths = torch.tensor([len(seq) for seq in features], dtype=torch.long)
    return features_padded, labels, lengths

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence


class RecXiEncoder(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(RecXiEncoder, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)  # Bidirectional LSTM -> hidden_dim * 2

    def forward(self, x, lengths):
        """
        Handles variable-length sequences using LSTM and packs/unpacks sequences.
        :param x: Padded input sequences [batch_size, max_seq_len, input_dim]
        :param lengths: Lengths of each sequence before padding [batch_size]
        :return: Encoded features [batch_size, hidden_dim]
        """
        packed_x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)
        packed_out, _ = self.lstm(packed_x)
        out, _ = pad_packed_sequence(packed_out, batch_first=True)  # [batch_size, max_seq_len, hidden_dim * 2]
        out = self.fc(torch.mean(out, dim=1))  # Mean pooling over the sequence
        return out  # [batch_size, hidden_dim]


class RecXiLayer(nn.Module):
    def __init__(self, input_dim, hidden_dim, identity_matrix=False):
        super(RecXiLayer, self).__init__()
        self.identity_matrix = identity_matrix
        self.transition_model = nn.Linear(hidden_dim, hidden_dim) if not identity_matrix else None

    def forward(self, z_t, prev_state, uncertainty, prev_precision):
        """
        Perform Gaussian inference for the RecXi layer.
        :param z_t: Observed data at time t [batch_size, hidden_dim]
        :param prev_state: Previous latent state [batch_size, hidden_dim]
        :param uncertainty: Measurement uncertainty matrix [batch_size, hidden_dim, hidden_dim]
        :param prev_precision: Previous precision matrix [batch_size, hidden_dim, hidden_dim]
        """
        batch_size, hidden_dim = z_t.size()

        if self.identity_matrix:
            predict_state = prev_state
            predict_precision = prev_precision
        else:
            predict_state = self.transition_model(prev_state)  # [batch_size, hidden_dim]
            predict_precision = torch.inverse(
                torch.matmul(self.transition_model.weight, prev_precision)
            )  # [batch_size, hidden_dim, hidden_dim]

        updated_precision = uncertainty + predict_precision  # [batch_size, hidden_dim, hidden_dim]

        # Reshape z_t for batch-wise matrix multiplication
        z_t = z_t.unsqueeze(-1)  # [batch_size, hidden_dim, 1]
        predict_state = predict_state.unsqueeze(-1)  # [batch_size, hidden_dim, 1]

        # Compute updated state
        updated_state = torch.matmul(
            torch.inverse(updated_precision),
            torch.matmul(uncertainty, z_t) + torch.matmul(predict_precision, predict_state)
        ).squeeze(-1)  # Remove last dimension, [batch_size, hidden_dim]

        return updated_state, updated_precision



class RecXiModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_speakers):
        super(RecXiModel, self).__init__()
        self.encoder = RecXiEncoder(input_dim, hidden_dim)
        self.layer1 = RecXiLayer(hidden_dim, hidden_dim, identity_matrix=True)  # Precursor
        self.layer2 = RecXiLayer(hidden_dim, hidden_dim, identity_matrix=False)  # Content disentanglement
        self.layer3 = RecXiLayer(hidden_dim, hidden_dim, identity_matrix=True)  # Disentangled speaker
        self.classifier = nn.Linear(hidden_dim, num_speakers)

    def forward(self, x, lengths):
        """
        Forward method for RecXiModel
        :param x: Padded input sequences [batch_size, max_seq_len, input_dim]
        :param lengths: Lengths of each sequence before padding [batch_size]
        """
        encoded_features = self.encoder(x, lengths)  # Encodes sequences into fixed-length representations

        # Initial state for Gaussian inference
        batch_size, hidden_dim = encoded_features.size()
        z_t = encoded_features
        prev_state = torch.zeros(batch_size, hidden_dim).to(x.device)
        uncertainty = torch.eye(hidden_dim).unsqueeze(0).repeat(batch_size, 1, 1).to(x.device)
        prev_precision = torch.eye(hidden_dim).unsqueeze(0).repeat(batch_size, 1, 1).to(x.device)

        # Layer 1: Precursor speaker representation
        precursor_state, precursor_precision = self.layer1(z_t, prev_state, uncertainty, prev_precision)

        # Layer 2: Content disentanglement
        content_state, content_precision = self.layer2(z_t, precursor_state, uncertainty, precursor_precision)

        # Layer 3: Disentangled speaker representation
        disentangled_state, disentangled_precision = self.layer3(
            z_t, content_state, uncertainty, content_precision
        )

        # Speaker classification
        speaker_logits = self.classifier(disentangled_state)  # [batch_size, num_speakers]
        return speaker_logits, precursor_state, content_state, disentangled_state

from sklearn.metrics import roc_curve
def cosine_similarity(a, b):
    """
    Compute cosine similarity between two tensors.
    :param a: Tensor of embeddings [batch_size, embedding_dim]
    :param b: Tensor of embeddings [batch_size, embedding_dim]
    :return: Cosine similarity scores [batch_size]
    """
    a_norm = F.normalize(a, p=2, dim=1)  # Normalize embeddings
    b_norm = F.normalize(b, p=2, dim=1)
    return torch.sum(a_norm * b_norm, dim=1)  # Dot product


def compute_eer(scores, labels):
    """
    Compute Equal Error Rate (EER).
    :param scores: Similarity scores
    :param labels: Ground truth labels (1 for same speaker, 0 for different speaker)
    :return: EER value
    """
    fpr, tpr, thresholds = roc_curve(labels, scores)
    fnr = 1 - tpr
    eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]
    eer = fpr[np.nanargmin(np.abs(fnr - fpr))]
    return eer, eer_threshold

def compute_min_dcf(scores, labels, p_target=0.01, c_miss=1, c_fa=1):
    """
    Compute Minimum Detection Cost Function (minDCF).
    :param scores: Similarity scores
    :param labels: Ground truth labels
    :param p_target: Prior probability of target speaker
    :param c_miss: Cost of a miss
    :param c_fa: Cost of a false acceptance
    :return: minDCF value
    """
    fpr, tpr, thresholds = roc_curve(labels, scores)
    fnr = 1 - tpr
    min_dcf = float('inf')

    for threshold in thresholds:
        miss = fnr[np.where(thresholds == threshold)[0][0]]
        fa = fpr[np.where(thresholds == threshold)[0][0]]
        dcf = p_target * c_miss * miss + (1 - p_target) * c_fa * fa
        min_dcf = min(min_dcf, dcf)

    return min_dcf

from tqdm import tqdm

def calculate_losses(speaker_logits, labels, precursor, disentangled_speaker):
    cls_loss = F.cross_entropy(speaker_logits, labels)  # Speaker classification loss
    ssp_loss = torch.norm((precursor - disentangled_speaker).pow(2).mean(dim=1))  # Frobenius norm for Lssp
    return cls_loss, ssp_loss

from tqdm import tqdm

def evaluate_model(model, train_loader, device):
    model.eval()
    all_scores, all_labels = [], []

    with torch.no_grad():
        for features, labels, lengths in tqdm(train_loader, desc="Evaluating", leave=False):
            features, labels = features.to(device), labels.to(device)
            lengths = lengths.cpu().long()

            # Forward pass
            speaker_logits, precursor, _, disentangled_speaker = model(features, lengths)

            # Calculate pairwise cosine similarity
            for i in range(disentangled_speaker.size(0)):
                for j in range(i + 1, disentangled_speaker.size(0)):
                    score = cosine_similarity(
                        disentangled_speaker[i].unsqueeze(0), disentangled_speaker[j].unsqueeze(0)
                    ).item()
                    label = 1 if labels[i] == labels[j] else 0
                    all_scores.append(score)
                    all_labels.append(label)

    # Compute evaluation metrics
    eer, eer_threshold = compute_eer(np.array(all_scores), np.array(all_labels))
    min_dcf = compute_min_dcf(np.array(all_scores), np.array(all_labels))
    return eer, min_dcf



def train_model(model, train_loader, eval_loader, num_epochs, learning_rate, alpha, beta, device):
    model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    for epoch in range(num_epochs):
        model.train()
        total_loss, total_cls_loss, total_ssp_loss = 0, 0, 0

        train_loader_tqdm = tqdm(train_loader, desc=f"Training Epoch {epoch + 1}/{num_epochs}", leave=False)

        for features, labels, lengths in train_loader_tqdm:
            features, labels = features.to(device), labels.to(device)
            lengths = lengths.cpu().long()

            optimizer.zero_grad()

            # Forward pass
            speaker_logits, precursor, _, disentangled_speaker = model(features, lengths)
            cls_loss, ssp_loss = calculate_losses(speaker_logits, labels, precursor, disentangled_speaker)

            # Backward pass
            total_loss_batch = alpha * cls_loss + beta * ssp_loss
            total_loss_batch.backward()
            optimizer.step()

            # Track losses
            total_loss += total_loss_batch.item()
            total_cls_loss += cls_loss.item()
            total_ssp_loss += ssp_loss.item()

            train_loader_tqdm.set_postfix(loss=total_loss_batch.item())

        # Epoch summary
        print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}, CLS Loss: {total_cls_loss:.4f}, SSP Loss: {total_ssp_loss:.4f}")

        # Evaluate on validation set
        eer, min_dcf = evaluate_model(model, eval_loader, device)
        print(f"Epoch {epoch + 1}: EER: {eer:.4f}, minDCF: {min_dcf:.4f}")

if __name__ == "__main__":
    # Parameters
    input_dim = 13  # MFCC features
    hidden_dim = 128
    num_epochs = 500
    learning_rate = 1e-4
    alpha, beta = 1.0, 0.5  # Loss weights
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load data
    train_dataset = SpeakerDataset("/content/drive/MyDrive/op.pkl")
    num_speakers = len(train_dataset.speaker_mapping)

    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)

    # Initialize model
    model = RecXiModel(input_dim, hidden_dim, num_speakers)

    # Train and evaluate on training dataset
    train_model(model, train_loader, train_loader, num_epochs, learning_rate, alpha, beta, device)